<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="The Neural Concept Binder derives discrete concept representations from raw input images.">
  <meta name="keywords"
    content="Neural Concept Binder, NCB, Concept Discovery, Interpretable Artificial Intelligence, Interactive Machine Learning, Disentanglement">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="YyDLtcGtegAATTYnhSXnvL6klnX3Bk00jCY9dZQxCTo" />
  <title>Neural Concept Binder</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/aiml_logo.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/fireworks.js"></script>

</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://ml-research.github.io">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://ml-research.github.io/pix2code/">
              Pix2Code
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Neural Concept Binder
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://ml-research.github.io/people/wstammer/index.html" target="_blank">Wolfgang
                  Stammer</a><sup>1,2,*</sup>,</span>
              <span class="author-block">
                <a href="https://ml-research.github.io/people/awuest/index.html" target="_blank">Antonia
                  W&uuml;st</a><sup>1,*</sup>,</span>
              <span class="author-block">
                <a href="https://ml-research.github.io/people/dsteinmann/index.html" target="_blank">David
                  Steinmann</a><sup>1,2,*</sup>,
              </span>
              <span class="author-block">
                <a href="https://ml-research.github.io/people/kkersting/" target="_blank">Kristian
                  Kersting</a><sup>1,2,3,4</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>AI/ML Group at TU Darmstadt,</span>
              <span class="author-block"><sup>2</sup>Hessian Center for AI (hessian.AI),</span>
              <span class="author-block"><sup>3</sup>Centre for Cognitive Science at TU Darmstadt,</span>
              <span class="author-block"><sup>4</sup>German Research Center for AI (DFKI)</span>
              <br />
              <span class="author-block"><sup>*</sup>Equal contribution</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.09949" class="external-link button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.09949" class="external-link button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ml-research/NeuralConceptBinder"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/AIML-TUDA/CLEVR-Sudoku"
                    class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <span>&#129303;</span>
                    </span>
                    <span>CLEVR Sudoku</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="content has-text-centered">
          <img src="./static/images/motivation.jpg" class="motivation-image" alt="Concept Learning Motivation" />

          <h3 class="subtitle has-text-centered">
            The <span class="method">Neural Concept Binder (NCB) </span> learns expressive yet inspectable
            and revisable concepts from unlabeled data.
          </h3>
        </div>
      </div>
    </div>
  </section>




  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                The challenge in object-based visual reasoning lies in generating concept representations
                that are both descriptive and distinct. Achieving this in an unsupervised manner requires
                human users to understand the model's learned concepts and, if necessary, revise incorrect
                ones. To address this challenge, we introduce the <span class="method">Neural Concept Binder</span>
                (NCB),
                a novel framework for deriving both discrete and continuous concept representations, which
                we refer to as “concept-slot encodings”. NCB employs two types of binding: “soft binding”,
                which leverages the recent SysBinder mechanism to obtain object-factor encodings, and subsequent
                “hard binding”, achieved through hierarchical clustering and retrieval-based inference.
                This enables obtaining expressive, discrete representations from unlabeled images.
                Moreover, the structured nature of NCB's concept representations allows for intuitive
                inspection and the straightforward integration of external knowledge, such as human input
                or insights from other AI models like GPT-4. Additionally, we demonstrate that incorporating
                the hard binding mechanism preserves model performance while enabling seamless integration into
                both neural and symbolic modules for complex reasoning tasks. We validate the effectiveness of
                NCB through evaluations on our newly introduced CLEVR-Sudoku dataset.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->

      </div>
    </div>
  </section>


  <section class="section">

    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Learn Expressive, yet Inspectable and Revisable Concepts</h2>

          <div class="content has-text-justified">
            <p>
              Our proposed <span class="method">Neural Concept Binder (NCB)</span> framework tackles the challenge of
              learning inspectable
              and revisable object-factor level concepts from unlabeled images by combining two key elements: (i)
              continuous representations via (block-)slot-attention based image processing with (ii) discrete
              representations via retrieval-based inference.
            </p>
            <div class="hero-body">
              <img src="./static/images/main.jpg" class="interpretability-image" alt="NCB Method overview" />
            </div>
          </div>
        </div>
      </div>
      <br />

      <!-- Video Embed Section -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">NCB Step by Step</h2>
          <video style="width: 100%; max-width: 1000px; height: auto;" controls>
            <source src="./static/images/Presentation_website.mp4" type="video/mp4">
            <p>Your browser does not support the video element. <a
                href="./static/images/Presentation_website.mp4">Download the video</a>.</p>
          </video>
        </div>
      </div>
      <!--/ Video Embed Section -->

      <!-- Interpretability. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Inspection of Learned Concepts</h2>

          <div class="content has-text-justified">
            <p>
              One key advantage of <span class="method">NCB's</span> concept representations is their inherent
              readability and inspectability.
              The concepts of an object can be inspected and compared to different concepts of the same block. For a
              more detailed understanding, concepts can even be swapped and new images based on the modified concept
              representation can be generated.
            </p>
            <div class="hero-body">

              <img src="./static/images/inspection.jpg" class="interpretability-image"
                alt="Concepts of an object can be inspected and compared." />
            </div>
          </div>

        </div>
      </div>
      <br />
      <!-- / Interpretability-->
  </section>
  <section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- CLEVR Sudoku -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">CLEVR Sudoku</h2>

            <div class="content has-text-justified">
              <p>
                We introduce the <span class="method">CLEVR Sudoku</span> dataset, a new benchmark that represents a
                challenging visual puzzle requiring both visual object perception and reasoning capabilitie. The dataset
                consists of 9x9 Sudoku puzzles with
                varying degrees of difficulty. Each image is annotated with the correct solution to the puzzle, which
                serves as the ground truth for evaluating the model's performance.
              </p>
              <p><strong>
                  CLEVR-Sudoku requires visual perception as well as deductive reasoning skills. Now you can try solving
                  the puzzles yourself directly on this website!
                  Simply place the images where you think they belong and see if its right!
                </strong></p>

              <!-- Call to Action Button -->
              <div class="has-text-centered">
                <a href="#sudoku-container" class="button is-primary is-large is-rounded">
                  <span class="icon">
                    <i class="fas fa-play-circle"></i>
                  </span>
                  <span>
                    Play CLEVR-Sudoku Now!
                  </span>
                </a>
              </div>
            </div>

            <!-- Sudoku -->
            <div class="hero-body">
              <div class="sudoku-wrapper">
                <div id="sudoku-container">
                  <div id="sudoku-grid"></div>
                  <div id="image-options"></div>
                </div>
              </div>
              <script src="./static/js/fireworks.js"></script>
              <script src="./static/js/script.js"></script>

              <!-- /Sudoku -->
            </div>
            <div class="content has-text-justified">
              <p>
                In our evaluations we show the solving <span class="method">CLEVR Sudoku</span> puzzles is harder than
                one
                might expect. Only small errors in the concept prediction (even in the case of supervised learning)
                cause
                a wrong symbolic representation of the grid and thus a wrong solution. With <span
                  class="method">NCB</span>
                we propose a
                strong baseline for solving the CLEVR Sudoku puzzles without supervision of the ground thruth concepts.
              </p>
            </div>

          </div>
        </div>
      </div>

    </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{stammer2024neural,
        title={Neural Concept Binder},
        author={Stammer, Wolfgang and W{\"u}st, Antonia and Steinmann, David and Kersting, Kristian},
        journal={Advances in Neural Information Processing Systems (NeurIPS)},
        year={2024}
      }
      </code></pre>
    </div>
  </section>

  <div id="modal" class="modal">
    <div class="modal-content">
      <span class="close">&times;</span>
      <p id="modal-message"></p>
      <canvas id="fireworks-canvas"></canvas>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/pdf/2406.09949">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/ml-research/NeuralConceptBinder" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This work was supported by the Priority Program (SPP) 2422 in the subproject “Optimization of active
              surface design
              of high-speed progressive tools using machine and deep learning algorithms“ funded by the German Research
              Foundation (DFG),
              the ”ML2MT” project from the Volkswagen Stiftung and the ”The Adaptive Mind” project from the Hessian
              Ministry of Science
              and Arts (HMWK). It has further benefited from the HMWK projects ”The Third Wave of Artificial
              Intelligence - 3AI”,
              and Hessian.AI, as well as the Hessian research priority program LOEWE within the project WhiteBox, and
              the EU-funded
              “TANGO” project (EU Horizon 2023, GA No 57100431).
            </p>
            <p>The website template is based on the source code of <a
                href="https://github.com/nerfies/nerfies.github.io">this
                website</a>. </p>
            <p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>